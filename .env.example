# Environment configuration for different LLM providers
# Copy this to .env and customize as needed

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Choose your provider: ollama, openai, gemini, openrouter
LLM_PROVIDER=ollama

# Global settings
LLM_TIMEOUT=300
LLM_MAX_TOKENS=1500
LLM_TEMPERATURE=0.7

# =============================================================================
# Ollama Configuration (Local models)
# =============================================================================
# Ollama is great for privacy and local execution
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma-3-12b-it-Q4_K_M:latest
# No API key needed for Ollama

# =============================================================================
# OpenAI Configuration
# =============================================================================
# Use OpenAI's powerful models (requires API key)
OPENAI_BASE_URL=https://api.openai.com
OPENAI_MODEL=gpt-4
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# Google Gemini Configuration
# =============================================================================
# Use Google's Gemini models (requires API key)
GEMINI_BASE_URL=https://generativelanguage.googleapis.com
GEMINI_MODEL=gemini-pro
GEMINI_API_KEY=your_gemini_api_key_here

# =============================================================================
# OpenRouter Configuration
# =============================================================================
# Access multiple models through OpenRouter (requires API key)
OPENROUTER_BASE_URL=https://openrouter.ai/api
OPENROUTER_MODEL=anthropic/claude-3-sonnet
OPENROUTER_API_KEY=your_openrouter_api_key_here

# =============================================================================
# Example configurations for popular models:
# =============================================================================

# For Claude via OpenRouter:
# LLM_PROVIDER=openrouter
# OPENROUTER_MODEL=anthropic/claude-3-sonnet

# For GPT-4 via OpenAI:
# LLM_PROVIDER=openai
# OPENAI_MODEL=gpt-4

# For local Gemma via Ollama:
# LLM_PROVIDER=ollama
# OLLAMA_MODEL=gemma-3-12b-it-Q4_K_M:latest

# For Gemini Pro:
# LLM_PROVIDER=gemini
# GEMINI_MODEL=gemini-pro
